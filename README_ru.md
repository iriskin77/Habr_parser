## Что это?

Основная идея - это создать набор cron-парсеров, которые могут периодически собирать новые статьи
с разных сайтов, используя API. Этот проект представляет собой api (Django REST) для парсеров, которые собирают данные (статьи) со следующих сайтов:

+ mel.fm https://mel.fm/
+ habr.com https://habr.com/ru/
+ tinkoff-journal https://journal.tinkoff.ru/


## Как это работает


#### Как работает API

POST запросы запускают следующие парсеры:

+ api/v1/pars_habr запускает парсер для сайта habr.com
+ api/v1/pars_mel запускает парсер для сайта  mel.fm
+ api/v1/pars_tink запускает парсер для сайта tinkoff-journal

Каждый парсер собирает статьи последовательно для каждой категории, которая добалвена в БД.
Например, для сайта habr.com можно добавить категории "программирование" и "математика" при помощи панели администратора Django. 
После этого парсер сначала соберет все статьи с главной страницы категории "программирование", потом все статьи с главной страницы
категории "математика", потом добавит их в БД. После этого другие сервисы могут обращаться к этим данным, используя API. Такой сервис
может использовать таймер, и парсер будет запускаться каждый 1/2/3 часа/дня/недели. Визуально это выглядит слеудющим образом:

![](https://github.com/iriskin77/Habr_parser_api/blob/master/images/dj_pars.png)

#### Как парсеры работают

Все парсеры работают почти одинаково. Парсер получает набор ссылок на категории. Например, категории "математика" или
"машинное обучение" для парсера, который парсит habr.com, или школа/образование для парсера, который парсит mel.fm.
После этого парсер последовательно обходит каждую категорию и собирает статьи. Визуально это выглядит следующим образом:

![](https://github.com/iriskin77/Habr_parser_api/blob/master/images/parser.png)

## Как установить

На данный момент можно установить только как python-script.

+ Клонировать репозитория

+ Установить виртуальное окружение:
  + python -m venv venv
  + .\venv\Scripts\activate (for windows)
  + source venv/biv/activate (for linux)

+ Установить зависимости: pip install -r requirements.txt

+ Применить миграции: python manage.py migrate

+ Создать супер-пользователя и добавить ссылки на категории, которые требуется спарсить

+ Запустить Celery и Redis

В проект добавлен swagger, при помощи него можно посмотреть описание API: swagger/

## Заметки

Возможные улучшения

+ Добавить Docker, чтобы было возможно установить проект олее простым способом. На данный момент это сделать довольно сложно...
+ Возможно разворачивание проекта на сервере
